---
title: "Assignment"
author: "K.Saketh Sai Nigam 22201204"
date: "2022-10-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exploratory Data Analysis:

**1. Using a boxplot, the density and the descriptive statistics (mean, min, max, median, and quantiles). Describe the distributions and the difference in the distributions for the percentage of school aged children that reported being happy with they way they are in 2006 with respect to sex (i.e. female vs male)?** 

```{r echo=FALSE}

#Read the data set  contained in a Assignment.csv file 
DX <- read.csv("/Users/saketh/Desktop/Assignment.csv")

DX1 <- subset(DX, Year == "2006")
DXM1 <- subset(DX1 , Sex == "Male")
DXF1 <- subset(DX1 , Sex == "Female")

#Descriptive statistics for Male and Female
summary(DXM1$P_Content)
summary(DXF1$P_Content)

#Boxplot of P_Content(The percentage of children that reported being happy with they way they are) with Respect to Sex(Male and Female)
boxplot(P_Content~Sex , data = DX1 ,main='Children who are happy with what they are in the year 2006',xlab = 'Sex' , ylab = 'Percentage Of Happy',col=c('green','yellow'))

#Density Plot for Sex(Male and Female)
library(ggplot2)
ggplot(data = DX1 , aes(x = P_Content)) + geom_density(aes(group=Sex, color = Sex))
density(DXM1$P_Content)
density(DXF1$P_Content)
plot(density(DXM1$P_Content),main = "Distribution of the Happy Males Percentage", 
     xlab = "Males Satisfaction Percentage", col = 'orange')
plot(density(DXF1$P_Content),main = "Distribution of the Happy Females Percentage", 
     xlab = "Females Satisfaction Percentage",col='green')
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*According to the density curve, the concentration of P_Content is highest at around 62 percent, which means that on average, 62 percentage of female children that reported being happy with they way they are in 2006.We may infer that the graph is normally distributed and that there is no skewness from the density curve. As a result, the median and mean are nearly equal.We may deduce from the density curve that it has a bimodal distribution, which means it has both a global and local maximum. According to the plot, there are two modes close to 40 and 70 here.We may infer that the graph is normally distributed and that there is no skewness from the density curve. As a result, the median and mean are nearly equal.The highest percentage of males who are happy is 74.37, while the highest percentage of females is 74.69, indicating that in 2006, the highest percentages of males and females who are happy are nearly identical. Averagely, a higher proportion of females than males report feeling cheerful.We may deduce from the box plot that, on average, in the year 2006, males have a satisfaction range of 53.72, while females have a satisfaction range of 63.98, indicating that females are more happy with what they have than males are.*

***-----------------------------------------------------------------------------------------------------------------------***

**2.Using a boxplot, the density and the descriptive statistics (mean, min, max, median, and quantiles). Describe the difference in the distributions for the percentage of female school aged children that reported being happy with they way they are with respect to year (2006; 2010; 2014; 2018)?**

```{r echo=FALSE}
DXFY4 = subset(DX, Sex == "Female" & Year %in% c(2006,2010,2014,2018))
DXMY4 = subset(DX, Sex == "Male" & Year %in% c(2006,2010,2014,2018))

#Boxplot of P_Content(The percentage of children that reported being happy with they way they are) of Female with Respect to Year
boxplot(P_Content~Year , data = DXFY4 , main='Happy females based on years', xlab = 'Year' , ylab = 'Percentage of females satisfied',col =c("orange","red","blue", "pink"))

DXF2010 = subset(DX, Sex == "Female"& Year %in% 2010)
DXF2014 = subset(DX, Sex == "Female"& Year %in% 2014)
DXF2018 = subset(DX, Sex == "Female"& Year %in% 2018)

#Density Plot for Female with respect to Year
plot(density(DXF1$P_Content), 
     main = "Density curve of Female Satisfaction in 2006,2010,2014,2018 years",
     ylim = range(0, 0.050))
lines(density(DXF2010$P_Content), col = "red")
lines(density(DXF2014$P_Content), col = "blue")
lines(density(DXF2018$P_Content), col = "pink")
legend("topright", c("2006", "2010", "2014", "2018"),
       col =c("orange","red","blue", "pink"), lty=1)

#Descriptive statistics for Female
summary(DXFY4$P_Content)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*We may deduce from the box plot that, on average, a higher percentage of women are content in the year 2014. In 2018, the lowest percentage of women report being cheerful. In general, about 50% of women are content in the years 2006, 2010, 2014, and 2018. On average, 47% of women are content in the years 2006, 2010, 2014, and 2018. In 2014, the proportion of cheerful females is distributed equally across the population.*

***-----------------------------------------------------------------------------------------------------------------------***

**3.Using a boxplot, the density and the descriptive statistics (mean, min, max, median, and quantiles). Describe the difference in the distributions for the percentage of male school aged children that reported being happy with they way they are with respect to year (2006; 2010; 2014; 2018)?**

```{r echo=FALSE}
#Boxplot of P_Content(The percentage of children that reported being happy with they way they are) of Male with Respect to Year
boxplot(P_Content~Year , data = DXMY4 , 
        main='Happy Males based on years',
        xlab = 'Year' , ylab = 'Percentage of Satisfactory Males',col =c("orange","red","blue", "pink"))

DXM2010 = subset(DX, Sex == "Male"& Year %in% 2010)
DXM2014 = subset(DX, Sex == "Male"& Year %in% 2014)
DXM2018 = subset(DX, Sex == "Male"& Year %in% 2018)

#Density Plot for Male with respect to Year
plot(density(DXM1$P_Content), 
     main = "Density curve of Male Satisfaction in 2006,2010,2014,2018 years",
     ylim = range(0, 0.050))
lines(density(DXM2010$P_Content), col = "red")
lines(density(DXM2014$P_Content), col = "blue")
lines(density(DXM2018$P_Content), col = "pink")
legend("topright", c("2006", "2010", "2014", "2018"),
       col =c("orange","red","blue", "pink"), lty=1)

#Descriptive statistics for Male
summary(DXMY4$P_Content)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*We may deduce from the box plot that on average, more men are content in the year 2006 than in any other. In the same vein, in 2018 the least number of women report being content. Across the years 2006, 2010, 2014, and 2018, a minimum of 28% of men report being content. Females are generally more content with their lives than males are, on the overall, throughout time. In the year 2018, both men and women are less happy with their current circumstances. In comparison to female kids, male kids exhibit a higher range in contentment.*

***-----------------------------------------------------------------------------------------------------------------------***

**4.Convert the categorical variable Sex to a factor. Describe and illustrate the frequency of the categorical variable Sex with respect to year (2006; 2010; 2014; 2018)?**
```{r echo=FALSE}
x <- as.factor(DXFY4$Sex)
table(x,DXFY4$Year)
y <- as.factor(DXMY4$Sex)
table(y,DXMY4$Year)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*We may deduce from the frequency table that there are the same numbers of men and women overall for all the years in the dataset (2006,2010,2014,2018)*

***-----------------------------------------------------------------------------------------------------------------------***

**5. Using the correlation and scatter plots discuss the relationship between P_Content and Year for males and females separately?**

```{r echo=FALSE}
DXM = subset(DX , Sex == "Male")
DXF = subset(DX , Sex == "Female")
cor.test(DXF$P_Content, DXF$Year)
cor.test(DXM$P_Content, DXM$Year)

ggplot(DXF, aes(x=Year, y=P_Content)) +
  geom_point()+ xlim(2004,2020)+ ylim(40,90)+ggtitle("The evolution of the female happiness percentage")

ggplot(DXM, aes(x=Year, y=P_Content)) +
  geom_point()+ xlim(2004,2020)+ ylim(40,90)+ggtitle("The evolution of the male happiness percentage")  

```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*The correlation between years and Female P Content is -0.1528523, and for men it is -0.141013, both of which show a weak negative association. The p value of 0.4414 for men, which is higher than the alpha, indicates that there is no correlation between age and the percentage of happy men. Similarly, the correlation for women is 0.4036, which is higher than the alpha and shows there is no connection between age and the proportion of happy women.There is no correlation between years and the proportion of content because all the values on the scatter plot for a given year are horizontal to one another.*

***-----------------------------------------------------------------------------------------------------------------------***

## Regression Model:

**1. Using R fit a simple linear regression model to the data with P_Content as the response variable and Year as a numeric predictor variable for females. Define and describe the terms in your mathematical equation for the model. (Also provide you R code)?**

```{r echo=FALSE}
V = scale(DXF$Year, center=TRUE, scale=FALSE)
mod <- lm(P_Content ~ V, data = DXF)
summary(mod)
ggplot(DXF, aes(Year, P_Content)) +
  geom_point() + 
  stat_smooth(method = lm) + xlim(2004,2020)+ggtitle("Relationship between percentage of females happy and years")
```


***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*One predictor variable and one response variable make up the straightforward linear regression model. The equation for the Simple Linear Regression is Y = Beta0 + Beta1X, where Beta0 is the Intercept and Beta1 is the slope.*

***-----------------------------------------------------------------------------------------------------------------------***

**2. Interpret the estimate of the intercept term?**

```{r echo=FALSE}
summary(mod)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*The mod's slope value of -0.2944 implies that for every unit rise in the average year, the overall anticipated P value will decrease by 0.2944, indicating a negative association. When seen in the context of the issue as the yearly average decreases the proportion of women who are cheerful, which increases*

***-----------------------------------------------------------------------------------------------------------------------***

**3. Interpret the estimate of the slope?**

```{r echo=FALSE}
coef(mod)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*The intercept is 62.6702, indicating that 2012 is the mean year for the mean P Value (i.e., the average percentage of females who are happy). Since the year cannot be zero, the intercept has no meaningful representation in the model, so we are using the average instead.*

***-----------------------------------------------------------------------------------------------------------------------***

**4. What is the standard error of a parameter? Calculate and comment on the standard error of the estimate of the intercept and slope term?**

```{r echo=FALSE}
summary(mod)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*The discrepancy between the actual and the estimated value is known as the standard error. The dispersion of the sample distribution's y variables around the regression line is indicated by the standard error of slope, which is 0.3475. The average deviation between the observed values and the regression line is 0.3475. The difference between the mean of the predicted value and the mean of the actual value is known as the standard error of the intercept. As a result, the difference between the mean of the actual value and the mean of the anticipated value is 1.5542.*

***-----------------------------------------------------------------------------------------------------------------------***

**5. Calculate and interpret the confidence intervals for β0?**

```{r echo=FALSE}
confint(mod,level = 0.95)
predict(mod,level=0.95,interval = "confidence")
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*The range of the confidence interval is 59.496293 to 65.8443324. This shows that we are 95% certain that the female population intercept is between the points 59.496293 and 65.8443324 (i.e., even if new data points are included, we are 95% certain that the mean percentage of happy females will be between 59.496293 and 65.8443324 according to the mean of years, which is 2012 (which cannot be 0)).*

***-----------------------------------------------------------------------------------------------------------------------***

**6. Calculate and interpret the confidence intervals for β1?**

```{r echo=FALSE}
confint(mod,level = 0.95)
predict(mod,level=0.95,interval = "confidence")
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*The range of the confidence interval is -0.100413 to 0.4153262. This shows that we are 95% certain that the female population slope is between -0.100413 and 0.4153262, (i.e., even if more data points are included, we are 95% certain that with an increase in the average year, the average percentage of happy females will fall between 0.100413 and 0.4153262).*

***-----------------------------------------------------------------------------------------------------------------------***

**7. What does the confidence interval of a parameter measure?**

*An estimate range for an unknown parameter is known as a confidence interval. The 95% confidence level is the most popular, however other levels, such 90% or 99%, are occasionally used when computing confidence intervals. The percentage of related CIs over the long run that include the parameter's actual value is represented by the confidence level. For instance, 95% of all intervals calculated at the 95% confidence level should include the parameter's actual value. The sample size, sample variability, and confidence level are all variables that have an impact on the confidence interval width. A larger sample would result in a narrower confidence interval if everything else remained the same.A confidence interval describes the probability that a population parameter would fall between a set of values for a given percentage of the time. It can be concluded that there is a 95% probability that the true value falls within that range if a point estimate of 10.00 is produced using a statistical model with a 95% confidence interval of 9.50 - 10.50.The probability that a parameter will fall between two values near the mean is shown by a confidence interval. Confidence intervals quantify how certain or uncertain a sampling technique is. They are also utilized in regression analysis and hypothesis testing.*


**8. Does a 95% confidence interval always contain the population parameter?**

*A range of data that you may be 95% confident contains the population's actual mean is known as a 95% confidence interval. This isn't the same as a range where 95% of the values are present.We are certain that the population parameter will be included in 95% of these intervals. However, we are unable to specify which ones without more details. We can therefore estimate that there is a 95% possibility that the population parameter will be included in our interval using only one sample and no more information about it.All of the generated datasets are unique; some intervals contain the real population parameter, while others do not.The mean of the population is one. As a result, it isn't really accurate to inquire about the chance that the population mean falls inside a particular range. On the other hand, the confidence interval you calculate is based on the data you just so happened to gather. Your confidence interval would almost probably be different if you ran the experiment again. It is therefore acceptable to inquire about the likelihood that the interval contains the population mean.*

**9. Compute and interpret the hypothesis test H0 : β0 = 0 vs Ha : β0 ̸= 0. State the test statistic. Compare the test statistic to the correct distribution value and state your conclusion. Also, report the p-value and the conclusion in the context of the problem?**

```{r echo=FALSE}
summary(mod)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*The t value obtained from the mod summary is 40.324, which is higher than the computed tvalue of the 95% confidence interval with degrees of freedom n-2 = 30. There will be an average p value, or the percentage of happy ladies, in the year 2012 as a result of our ability to reject the null hypothesis in this situation and p value is 5% lower than alpha. 0.05 indicates that the null hypothesis should be rejected because it is improbable.*

***-----------------------------------------------------------------------------------------------------------------------***

**10. Compute and interpret the hypothesis test H0 : β1 = 0 vs Ha : β1 ̸= 0. State the test statistic. Compare the test statistic to the correct distribution value and state your conclusion. Also, report the p-value and the conclusion in the context of the problem?**

```{r echo=FALSE}
summary(mod)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*There is no correlation between the P value and the year because H0 is null and Beta1 is equal to 0. Ha - Be the alternative hypothesis that suggests a connection exists between the P-value and the year. A t value of -0.847 is obtained from the mod summary, which is smaller than the computed t value of the 95% confidence interval with degrees of freedom n-2 = 13. There is no proper relationship between the year and the P Content in this situation, thus we are unable to reject the null hypothesis. Since the null hypothesis is more likely than alpha = 5%, or 0.05, the p value is greater than alpha, and we can accept it.*

***-----------------------------------------------------------------------------------------------------------------------***

**11. Interpret the F-statistic in the output in the summary of the regression model. Hint: State the hypothesis being tested, the test statistic and p-value and the conclusion in the context of the problem?**

```{r echo=FALSE}
summary(mod)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*H0, or the null hypothesis, states that there is no association between the two variables because Beta 1 is equal to zero in the reduced mode. Beta 1 is not equal to 0 in the whole model, which indicates that there is a strong association between the two variables. This is the alternate hypothesis, or HA.*

***-----------------------------------------------------------------------------------------------------------------------***

**12. Interpret the R-squared value?**

```{r echo=FALSE}
summary(mod)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*We can find out from the R-squared number how much of the variation in y is explained by its relationship with x. The R-squared value obtained from the model is 0.02336, indicating that just around 2% of the variation in the values of y can be attributed to the link with x.Here because there are multiple predictor variables, we examine the Normal R Squared value rather than the Adjusted R Squared Value.*

***-----------------------------------------------------------------------------------------------------------------------***

**13. Interpret the residual standard error of the simple linear regression model.?**

```{r echo=FALSE}
summary(mod)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*The average discrepancy between the expected and actual values of Y is known as residual standard error. The average difference between the projected Y value and the actual Y value is 8.792 on a 30 degree scale.*

***-----------------------------------------------------------------------------------------------------------------------***

**14. Calculate, plot and comment on the shape of the prediction intervals for the estimated values of Y (Provide you R code)?**

```{r echo=FALSE}
predict(mod,level=0.95,interval = "prediction")
p <- predict(mod, interval = "prediction")
q <- cbind(DXF, p)
r <- ggplot(q, aes(Year,P_Content)) +geom_point() +stat_smooth(method = lm)
r + geom_line(aes(y = lwr), color = "brown")+
  geom_line(aes(y = upr), color = "brown")
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*The interval is broader, but the fitted value is the same as before. Furthermore, it should be highlighted that while prediction and confidence intervals both foretell a response, they differ in terms of how that response is expressed and perceived.Here, a simple linear regression model's prediction intervals and its plot are explained.The prediction interval of the estimated value of Y is represented by the brown lines with the shape of line slightly goes down as years pass on. As intervals are given more information, the predictions are frequently a far more helpful representation of the information.*

***-----------------------------------------------------------------------------------------------------------------------***

## Regression Model Diagnostics:

**1. Are there any influential observations?**

```{r echo=FALSE}
s = nrow(DXF)
cs <- cooks.distance(mod)
plot(cs, pch="#", cex=2, main="Influential obs by Cooks distance")
abline(h = 4/s, col="pink") 
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*By using Cook's distance, we can verify that the dataset is devoid of outliers overall and that no significant points exist.*

***-----------------------------------------------------------------------------------------------------------------------***

**2. Examine the residuals of the regression model and comment on whether you think the residuals satisfy the assumptions required for small sample inference. Provide the rationale for your answer?**

```{r echo=FALSE}
boxplot(residuals(mod), main="Residuals",col='azure')
summary(mod)
qqnorm(residuals(mod),main="QQ plot",pch=19,col='purple')
qqline(residuals(mod),col='cyan')
shapiro.test(residuals(mod))
plot(density(residuals(mod)),main="Residuals Density Plot")
polygon(density(residuals(mod)), col="bisque")
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*Given the area difference between the median and Q3 Q1 and median, we may deduce from the residual box plot that the residuals have a somewhat negative residual. Because of how little it is, we may say that the residual is normally distributed. The data points are organized closely to the line denoting a normal distribution, as can be seen from the QQ plot. The P-value for the Shapiro test, which is less than the alpha value and indicates that the data's distribution is significantly different from a normal distribution, is 0.04748. From the density plot we can infer that the residuals are not centred around 0.So there is no normal distribution.*

***-----------------------------------------------------------------------------------------------------------------------***

**3. Based on the information in Q2. How could you use the other information in the dataset to potentially improve your simple linear regression model?**

```{r echo=FALSE}
g = as.numeric(gsub("([0-9]+).*$", "\\1", DXF$Age))
cor.test(DXF$P_Content,g)
```

***-----------------------------------------------OBSERVATIONS-----------------------------------------------***

*'Age' from the dataset can be used as the new predictor variable. The correlation value of -0.9211129, which denotes a strong negative correlation, tells us that as women's ages rise, the proportion of women who are content with their lives as they currently stand sharply declines.*

***-----------------------------------------------------------------------------------------------------------------------***









I "Saketh Sai Nigam Kanduri" confirm that this assignment is my own work. I have not copied in part or whole or otherwise plagiarised the work of other students and/or persons. I confirm that I have read and understood the UCD School of Mathematics and Statistics regulations on plagiarism in the Week 5 folder on bright space.
